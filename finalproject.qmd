---
title: "Final Project"
author: "Christina Yu, Damian Kim"
format: pdf
---


## Read in the data

```{r read-data, message = F, warning = F}
library(tidyverse) 
library(ggfortify)
library(knitr)
library(broom)
library(patchwork)
library(tidymodels)
library(corrplot)
library(nnet)
library(car)
library(mice)
library(naniar)
library(UpSetR)
data <- read_csv("data/movies.csv")
```

## Introduction and data


With the rise in the age of information, the processing speeds of data are accelerated to impossible levels. One of the densest forms of media content out there is the transcription of words into pixels. A book that previously took 2 weeks to finish now fits in the span of 2 hours in the insanely digestible form of: movies. The movie industry is worth 95 billion dollars in the US alone, and indeed there is a great demand for quality movies. Though it is not easily apparent to tell what makes a movie great, there are some basic data that might help determine some of the factors of a great movie. We decided to try and tackle this heavy yet essential question. What factors might help make a movie successful? Throughout this project we can consider this question through the lens of a potential movie investor.

This dataset was scraped from IMDb (Internet Movie Database). There are 6820 movies in the dataset (220 movies per year, 1986-2016). Each movie has the following attributes:

-- `budget`: the budget of a movie. Some movies don't have this, so it appears as 0

-- `company`: the production company

-- `director`: the director

-- `genre`: main genre of the movie.

-- `gross`: revenue of the movie

-- `name`: name of the movie

-- `rating`: rating of the movie (R, PG, etc.)

-- `released`: release date (YYYY-MM-DD)

-- `runtime`: duration of the movie

--  `score`: IMDb user rating

-- `votes`: number of user votes

-- `star`: main actor/actress

-- `writer`: writer of the movie

-- `year`: year of release

We will explore the factors that make a movie successful through examining the effects of our variaables of interest: `gross`, `budget`, `genre`, `rating`,`score` `votes`, and `runtime` for individual movie. 

First we will explore missingness in our dataset.
```{r missingness, message = F, warning = F}
vis_miss(data)
gg_miss_upset(data)
gg_miss_fct(x = data, fct = genre)
```


The dataset includes movies that haven't been published yet (which causes a missing gross value). In our project we are considering gross revenue of a movie as the defining indicator of success. Considering that, we removed all observations that haven't been published yet or are missing gross values, because we are interested only in movies with a quantitative measure of success. 

In fact, we also decided to rid our dataset of missing values for the other predictor variables as well. About 28% of the observations were missing a value for budget, whereas the next most missing variable was gross, with 2%. From elementary missingness analysis there did not seem to be very strong, numerically significant relationships between the missingness of each variable with other variables of interest. Though it is unlikely that the missingness of our budget data in particular was MCAR (generally unlikely in the real world, perhaps lower budgets were less public and thus less likely to have solid budget details), we decided to do a complete case analysis. From our data it was hard to tell if the dataset could be assumed to be MAR. Though there might be some bias introduced, since we were working with such a large number of movies, we decided it was okay to lose some validity of our model. Obviously this is a big limitation of our project, and if such a project were done again we would be more meticulous. Now we have 5423 observations in the dataset.

```{r filter-data}
data <- data %>%
  filter(!is.na(gross) & !is.na(budget) & !is.na(genre) & !is.na(rating) & !is.na(score) & !is.na(votes) & !is.na(runtime) & !is.na(country))
```

## The Predictor Variables
We will use the `budget`, `genre`, `rating`,`score` `votes`, `runtime`, and `country` variables as predictors. Among them, `budget`, `score` `votes`, and `runtime` are numerical variables, while `genre`, `rating`, and `country` are categorical variables.

## The Response Variable
As described earlier, the `gross` numerical variable is our response variable.
1. Summary of the `gross` variable: 
```{r vis-gross}
data %>% 
  summarise(mean_gross = mean(gross),
            median_gross = median(gross),
            sd_gross = sd(gross),
            min_gross = min(gross),
            max_gross = max(gross)) %>% 
  kable()
```


2. Log-transformation and Distribution of the `gross` variable: 
```{r distribution-gross}
data <- data %>% 
  mutate(log_gross = log(gross)) %>%
  mutate(mean = mean(log_gross)) 

p1 <- ggplot(data = data, aes(x = gross))+
  geom_histogram(fill = "light blue", color = "black")+
  labs(title = "Distribution of Movies' Gross",
       x = "Gross")
p2 <- ggplot(data = data, aes(x = log_gross))+
  geom_histogram(fill = "light blue", color = "black")+
  labs(x = "Log (Gross)")
p1/p2

```
```{r gross-distributions, message = F, warning = F}
ggplot(data = data) + 
  geom_boxplot(aes(y = gross, color = genre)) +
  labs(title = "Gross", 
       color = "Genre")

ggplot(data = data) + 
  geom_boxplot(aes(y = log_gross, color = genre)) +
  labs(title = "Log Gross", 
       color = "Genre")
```


Since the response variable is significantly right skewed, we apply a log-transformation to it and will use log(gross) as our new response variable in the future analysis. Now, our response variable is unimodal, following a roughly normal distribution, with a mean at 17.2102, and there exist some outliers on the left end. 

3. Relationship between Gross and Budget based on different Genres & Ratings: 
```{r relationship-gross-budget-genres, message = F, warning = F}
ggplot(data = data, aes(x=budget, y = gross, color = rating))+
  geom_point(size=0.5, fill=NA) +
  geom_smooth(fill=NA) +
  theme(legend.key.size = unit(0.3, "cm")) +
  facet_wrap(~ genre)+
  ggtitle("Relationship between Budget and Gross by Rating across Genres") +
  xlab("Budget") +
  ylab("Gross")+
  scale_color_discrete(name = "Rating", guide = guide_legend(override.aes = list(size = 1)))+
  theme(panel.spacing.x = unit(2, "mm"))
```
We observe that the relationship between budget and gross is vastly different across genres: action, adventure, animation movies have a steep slope and generally high budget ranges, with outliers which have exceedingly high budget and relatively high gross values. Noticeably, there are also a lot more movies in these three categories, with the most in action. On the other hand, genres such as horror, mystery and romance have a visibly flatter slope, which corresponds to the industry knowledge that certain genres are more conducive to low-budget film making than others, even when provided with additional funding. Thus, we're interested in further exploring the relationship between budget, genre, and success.

## EDA: Visualizatioins and Summary Statistics
The dataset contains many interesting variables that we want to explore fully. We will first do some elementary exploratory data analysis on our datasets to show potential insights that we can explore further.

```{r numeric-variable-distributions, message = F, warning = F}
ggplot(data = data) + 
  geom_boxplot(aes(y = score, color = genre)) +
  labs(title = "Score", 
       color = "Genre")

ggplot(data = data) + 
  geom_boxplot(aes(y = votes, color = genre)) +
  labs(title = "Votes", 
       color = "Genre")

ggplot(data = data) + 
  geom_boxplot(aes(y = budget, color = genre)) +
  labs(title = "Budget", 
       color = "Genre")

ggplot(data = data) + 
  geom_boxplot(aes(y = runtime, color = genre)) +
  labs(title = "Runtimes", 
       color = "Genre")

```
As can be seen, the score variable is relatively unskewed, whereas the votes, budget, and runtime variables are heavily positively-skewed. 

```{r interesting-relationships, message = F, warning = F}
data2 <- data %>% 
  mutate(log_votes = log(votes)) 

ggplot(data = data, aes(x = runtime, y = gross)) + 
  geom_point() +
  labs(title = "Runtime has no relationship with Gross")

data2 <- data %>% 
  mutate(log_votes = log(votes)) 

ggplot(data = data2, aes(x = log_votes, y = score)) + 
  geom_point() +
  labs(title = "Log of votes has a converging, positive relationship with Score")
```

```{r correlation-matrix, message = F, warning = F}

numeric_data <- data |> 
  select("score", "votes", "budget", "gross", "runtime")
corrplot(cor(numeric_data))

```
As can be seen, we have some correlated variables between our predictor variables, but none are particularly strong (0.8+) so we don't have to remove any of these predictor variables on the basis of correlation for our later models. Though there seem to be no particularly strong correlations between predictor variables, the strongest correlation is between votes and score. We may consider adding this into our model because it also fits with our domain knowledge that a movie that is rated by more people might generally have a higher score because, in our experience, people are more motivated to rate a movie they enjoy than one they dislike. 

## Methodology
As a potential movie investor, we're obviously curious about the prediction of movies' success, and the factors that lead to success. Therefore, we want to explore the following topics in detail in order for us to be better investors: 1) Prediction of movies' gross value 2) the factors that affect the success of the movie. Some of the methods by which we are going to tackle this is through linear regression, residual plots, linear mixed models, LASSO, and repeated k-fold validation.

## LASSO (Variable Selection):
As mentioned above we are interested in the relationships between the variables and success, but we still wish to filter variables that are more likely to have a significant effect on our model. Therefore, we will apply a LASSO variable selection process in order to determine significant variables to explore.
```{r lasso, message = F, warning = F}
set.seed(919)
library(glmnet)
y <- data$log_gross
x <- model.matrix(log_gross ~ budget + genre + rating + score + votes + 
                    runtime + country, data = data)

m_lasso_cv <- cv.glmnet(x, y, alpha = 1)
best_lambda <- m_lasso_cv$lambda.min
best_lambda

m_best <- glmnet(x, y, alpha = 1, lambda = best_lambda)
m_best$beta
```
Some coefficients of the categories of the variables of genre, rating, and country have coefficients were shrunk to zero. Our data is processed in a way where an observation can take only one "level" of a category, for example, a movie can only have one genre. Since even one of the factors of the genre, rating, or country variables has been excluded, we will remove those factor variables as a whole. This is because LASSO performs feature selection, and for a factor variable such as genre, which is set with a baseline of "action", a singular comparison of, say, adventure vs action is not a feature, rather, the comparison of the entire variable versus action is a feature. This is somewhat of an all or nothing approach, that we could potentially avoid with dummy coding, contrast coding, or Helmert coding, however in the context of this class we thought it was okay to go with our approach. Similar logic applies to rating, with a baseline of "approved", and country, with a baseline of "Argentina". Our model therefore contains, after LASSO selection, the variables of budget, score, votes, and runtime. 

## Linear Regression of all variables
Gross revenue is a continuous response variable, so we will first examine a linear regression model for our data. We've gained the equation of XX.  

```{r linear-regression-variables, message = F, warning = F}
m1 <- lm(log_gross ~ log(budget) + score + log(votes) + log(runtime), 
         data = data)
m1_aug <- augment(m1)
summary(m1)

rmse(m1_aug, truth = `log_gross`, estimate = .fitted)
```
$\widehat{Gross} = \beta_0	+ \beta_1 * log(budget) + \beta_2 * score + \beta_3 * log(votes) + \beta_4 * log(runtime)$

## Residual plots/Assumptions
```{r residual-plot, message = F, warning = F}
ggplot(m1_aug, aes(x = .fitted, y = .resid)) + 
  geom_point() + 
  geom_hline(yintercept = 0, color = "darkred") + 
  labs(x = "Fitted (predicted) value", y = "Residual") + 
  theme_bw()

ggplot(m1_aug, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() + 
  theme_bw() + 
  labs(x = "Theoretical quantiles", 
       y = "Sample quantiles")
```
We may assume that each movie is independent of each other. We can see that the linear assumption is violated since the data is not symmetrically distributed observations around the horizontal axis. The linearity, constant variance, and  normality is not satisfied from the above graph. In order to address the normality violation, we did log transformation for our response variable to be `log_gross`. In order to address this problem, we use log transformation to our heavily skewed numeric variables, and in this way, the linearity residual plot is improved, while the constant variance and normality is still violated. 

We acknowledge it --  limitations XXX

## Linear Mixed Model & Random Effect
Since we have the country, genre, and rating these three categorical variables have too many levels, for example, for United States, we have XXX data records, and for XX country, we only have XX variables, so it would make more sense for use to use these three variables as random effects, we want to apply linear mixed model to our datasets to further explore our questions. We want to look at the associations between our interested variables, and random effect due to country, genre, and rating.

```{r random-effect, message = F, warning = F}
library(lme4)
m4 <- lm(log_gross ~ budget + genre + rating + score + votes + runtime + country, data = data)
m5 <- lmer(log_gross ~ 1 + budget + (1 | genre) + (1 | rating) + score + votes + runtime + (1 | country), data = data)
summary(m4)$coef
summary(m5)

r.rmse4 <- sqrt(mean(residuals(m4)^2))
r.rmse5 <- sqrt(mean(residuals(m5)^2))


m4_aug <- augment(m4)
rmse(m4_aug, truth = `log_gross`, estimate = .fitted)

```
```{r model-compare, message = F, warning = F}
library(lme4)
r.rmse4 <- sqrt(mean(residuals(m4)^2))
r.rmse5 <- sqrt(mean(residuals(m5)^2))
r.rmse4
r.rmse5
```
Compare model: since we can see that for linear regression, it has smaller RMSE as 1.3523 < 1.3575. We would conclude that model 1 is better than better 2 (linear regression better than the linear mixed model). However, the difference between RMSE is subtle. 

While adjusting for the random intercept based on country variable and holding all other variables constant, we noticed that the estimated variance is 0.1623 which means that all the country-specific intercept is distributed around the model's overall intercept within estimated variance of 0.1623, given that our unit is log dollars, and our estimated variance is quite small, we may expect that the country is similar. In terms of our interest in knowing whether a movie is successful or not, production of country may not be a big effect on the movie's success.

Since we noticed that genre has the smallest estimated variance (0.08254), we may say that compared to the difference between ratings and countries, the difference between genres is smaller, while rating has the biggest difference. Given that our unit is log dollars, and all of our estimated variance is quite small, the differences between these variables should be similar to each other. 

## Interested Hypothesis Test 1:
Question 1: Is there evidence to suggest that log(Budget) has an effect on the success of the movies?
Null hypothesis: $p_1 = 0$ There isn't sufficient evidence to suggest that budget is associated with movies' gross, while controlling for all of the variables.
Alternative hypothesis: $p_1 ≠ 0$ There is sufficient evidence to suggest that budget is associated with movies' gross, while controlling for all of the variables.

We use significance level of 0.05. Since the t-statistics is 23.227 and the p-value is < 2e-16 which is much smaller than our significance level, so we reject the null hypothesis since there's sufficient evidence, and thus there's sufficient evidence to suggest to log(budget) does have an effect on the success of the movies (log(gross)).

In terms of qualitatively addressing this issue: in our model, we know that every $1$ million increase in our budget, the gross value is expected to increase by $e^{cc}$ dollars.
## Interested Hypothesis Test 2:
Aim 2: Is there evidence to suggest that log(Score) has an effect on the success of the movies?
Null hypothesis:  $p_2 = 0$ There isn't sufficient evidence to suggest that Score is associated with movies' gross, while controlling for all of the variables.
Alternative hypothesis: $p_2 ≠ 0$ There is sufficient evidence to suggest that Score is associated with movies' gross, while controlling for all of the variables.

We use significance level of 0.05. Since the t-statistics is 23.227 and the p-value is 3.06e-09 which is much smaller than our significance level, so we reject the null hypothesis since there's sufficient evidence, and thus there's sufficient evidence to suggest to genre does have an effect on the success of the movies. 

## Summary based on Hypothesis: 
Based on our previous two hypothesis, we noticed that XXXXX. 


## Predicting moves' gross
Based on all the models we've done above, we've analyzed the relationship between different variables that we're interested in. In order to make our findings applicable for future use, we'd like to make a prediction on movies' gross based on our current variables. 

```{r prediction-gross, message = F, warning = F}
set.seed(123)
dim(data)

indices <- sample(1:5423, size = 5423 * 0.8, replace = F)
train.data  <- data %>% 
  slice(indices)
test.data <- data %>% 
  slice(-indices)
dim(train.data)

library(caret)
cv_method <- trainControl(method = "cv", number = 10,
                          repeats = 5)
m1 <- train(log_gross ~ budget + genre + rating + score + votes + runtime + 
              country, data = data, method = "lm", trControl = cv_method)
m2 <- train(log_gross ~ budget + genre + rating + score + votes + runtime + 
              country, data = data, method = "lm", trControl = cv_method)

print(m2)

library(caret)
cv_method <- trainControl(method = "cv", number = 10,
                          repeats = 5)
m3 <- train(log_gross ~ log(budget) + genre + rating + log(score) + log(votes) +
              log(runtime) + country, 
            data = data, method = "lm", trControl = cv_method)
m4 <- train(log_gross ~ log(budget) + genre + rating + log(score) + log(votes) +
              log(runtime) + country, 
            data = data, method = "lm", trControl = cv_method)

print(m4)
```

The RMSE from first model is XXX; while the RMSE from the second model is XXXX. Since the second one is smaller, the second one is better performing model in predicting the gross values of the movie. XXXX Since better, we might use log/ or fewer variables in predicting our gross values. 

## Results
Explain the reasoning for the type of model you’re fitting, predictor variables considered for the model including any interactions. Additionally, show how you arrived at the final model by describing the model selection process, interactions considered, variable transformations (if needed), assessment of conditions and diagnostics, and any other relevant considerations that were part of the model fitting process.

## Discussion & Limitations 
Summary + statistical arguments to support my conclusions + future limitations/future ideads

Variable selection, specifically the lasso for categorical variables with 2+ levels,
Rescaling predictor variables,
linearity assumptions,




## Sources
https://towardsdatascience.com/feature-selection-in-machine-learning-using-lasso-regression-7809c7c2771a
https://stackoverflow.com/questions/13646654/root-mean-square-error-in-r-mixed-effect-model
https://psyarxiv.com/wc45u/


